#!/bin/bash

#SBATCH --job-name=bam     ## Name of the job.
#SBATCH -p standard          ## partition/queue name
#SBATCH -A vswarup_lab           ## partition/queue name
#SBATCH --nodes=1            ## (-N) number of nodes to use
#SBATCH --ntasks=1          ## (-n) number of tasks to launch
#SBATCH --cpus-per-task=32    ## number of cores the job needs
#SBATCH --error=slurm-%J.err ## error log file
#SBATCH --mem 64G              ## request 64GB of memory
#SBATCH --array=0-14
#SBATCH --time=72:00:00

module load samtools

cd /dfs3b/swaruplab/smorabit/analysis/PiD_2021/trackhubs/

# directory with .tsv files contgaining lists of bams to merge
bam_list_dir="/dfs3b/swaruplab/smorabit/analysis/PiD_2021/trackhubs/data/bam_merge_lists/"

# merged bam output dir
outdir="/dfs3b/swaruplab/smorabit/analysis/PiD_2021/trackhubs/data/bams/merged/"
mkdir $outdir

# select barcodes file based on the task array:
groups=($(ls $bam_list_dir))

# get current sample based on the SLURM job ID
let index="$SLURM_ARRAY_TASK_ID"
group=${groups[$index]}
group=$(basename $group .tsv)
echo $group

# merge
samtools merge \
  --threads 32 \
  -b $bam_list_dir$group".tsv" \
  $outdir$group".bam"

# index:
samtools index -@ 32 $outdir$group".bam"
